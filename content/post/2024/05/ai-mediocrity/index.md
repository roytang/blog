---
title: "\"AI\"/LLM Mediocrity"
date: 2024-05-20T20:09:49+08:00
draft: true
---

I recently [shared and quoted from](https://roytang.net/2024/05/997ac087acc16c16a6bb5ce729b21e25/) a link to Molly White's newsletter: [AI isn't useless. But is it worth it?](https://www.citationneeded.news/ai-isnt-useless/)

The article is filled with a lot of good examples, but I want to highlight something in particular, regarding text generation using LLMs, that I don't especially agree with:

> But I think most people, myself certainly included, would be mortified to replace any of our writing with this kind of stuff.
>

I think "most people" is doing a lot of heavy lifting here. I think it's something closer to the opposite: I think that most people view the idea of reading or writing anything longer than a tweet to be a chore they would rather not do [^1], and it's to those kinds of people that the idea of LLM text generation appeals the most, which is why it is so easy to build up hype around it. (And why our modern online society is so focused around short-form videos and memes and microblogging, but that's a rant for another day.)

The way LLM text generation works is that they string words together to imitate sentences in a probabalistic manner. As a consequence, the text generated by these models will tend to skew towards an average level of quality. That is, you are probably getting something approaching the output of a mediocre writer. 

And assuming these models are trained on the internet at large, one largely already populated by clickbait sites designed to farm engagement and views and ad clicks, the "mediocre writer" output generated by these LLMs will tend to be... well, pretty bad. And since these models also enable similar content generation at even larger scales, this average level of quality will tend to reinforce itself!

Given that text generated by LLM is akin to a mediocre writer, the people most likely to benefit using such models would be... less than average writers. That is, the majority of the population who don't actually care for reading and writing as meaningful activities. 

Based on what I've read of her work, Molly White is a pretty good writer, so she is probably generalizing through that lens. Her statement is probably better rephrased as "most halfway decent writers would be mortified to replace any of our writing with this kind of stuff".

(It is a bit arrogant, but I not-so-humbly include myself among the "most halfway decent writers" category here.)

That being said, a lot of companies may think this kind of "mediocre writer"-generated text is "good enough" for their needs and find themselves dazzled by the idea of saving on labor costs such models promise. But the real measure of how useful these models really are would be the success stories. Chat-GPT has been out since November 2022, more than a year and a half now, and aside from tech companies hoovering up investments from trend-blinded venture capitalists, I have yet to hear of very big success stories. Where are the companies announcing record profits because they saved so much money converting their call centers to chat bots? Where are the large-scale software projects that were delivered early because of the programmers using Copilot? Where are the best-selling ChatGPT-generated novels?

And all of this comes at huge costs. As an example, [Microsoft recently disclosed a 29% emissions increase since 2020](https://www.axios.com/2024/05/16/microsoft-ai-data-center-power), mostly driven by AI-related demand. Huge amounts of energy and water going to power these systems so we can generate more mediocre writing that most people don't want to read anyway (and further pollute the internet on the way), how is any of this worth it?

[^1]: I also think this attitude is a major source of "meetings that could have been emails"